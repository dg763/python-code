{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   RI      214 non-null    float64\n",
      " 1   Na      214 non-null    float64\n",
      " 2   Mg      214 non-null    float64\n",
      " 3   Al      214 non-null    float64\n",
      " 4   Si      214 non-null    float64\n",
      " 5   K       214 non-null    float64\n",
      " 6   Ca      214 non-null    float64\n",
      " 7   Ba      214 non-null    float64\n",
      " 8   Fe      214 non-null    float64\n",
      " 9   Type    214 non-null    int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 16.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       " 0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       " 1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       " 2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       " 3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       " 4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1,\n",
       "                RI          Na          Mg          Al          Si           K  \\\n",
       " count  214.000000  214.000000  214.000000  214.000000  214.000000  214.000000   \n",
       " mean     1.518365   13.407850    2.684533    1.444907   72.650935    0.497056   \n",
       " std      0.003037    0.816604    1.442408    0.499270    0.774546    0.652192   \n",
       " min      1.511150   10.730000    0.000000    0.290000   69.810000    0.000000   \n",
       " 25%      1.516522   12.907500    2.115000    1.190000   72.280000    0.122500   \n",
       " 50%      1.517680   13.300000    3.480000    1.360000   72.790000    0.555000   \n",
       " 75%      1.519157   13.825000    3.600000    1.630000   73.087500    0.610000   \n",
       " max      1.533930   17.380000    4.490000    3.500000   75.410000    6.210000   \n",
       " \n",
       "                Ca          Ba          Fe        Type  \n",
       " count  214.000000  214.000000  214.000000  214.000000  \n",
       " mean     8.956963    0.175047    0.057009    2.780374  \n",
       " std      1.423153    0.497219    0.097439    2.103739  \n",
       " min      5.430000    0.000000    0.000000    1.000000  \n",
       " 25%      8.240000    0.000000    0.000000    1.000000  \n",
       " 50%      8.600000    0.000000    0.000000    2.000000  \n",
       " 75%      9.172500    0.000000    0.100000    3.000000  \n",
       " max     16.190000    3.150000    0.510000    7.000000  ,\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "glass_data = pd.read_csv(r'D:\\files\\glass.csv')\n",
    "\n",
    "# Display the first few rows of the dataset and summary statistics\n",
    "glass_data.head(), glass_data.describe(), glass_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2: (0.5581395348837209, 0.36666666666666664, 1.0),\n",
       " 0.3: (0.813953488372093, 0.5789473684210527, 1.0),\n",
       " 0.4: (0.7441860465116279, 0.5, 0.6363636363636364),\n",
       " 0.5: (0.6976744186046512, 0.3333333333333333, 0.18181818181818182),\n",
       " 0.6: (0.7209302325581395, 0.4, 0.18181818181818182),\n",
       " 0.7: (0.6976744186046512, 0.0, 0.0),\n",
       " 0.8: (0.7209302325581395, 0.0, 0.0)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Prepare the data\n",
    "X = glass_data[['Al']]  # Predictor\n",
    "y = glass_data['Type']  # Target\n",
    "\n",
    "# Since 'Type' is multiclass, we'll make it a binary problem for this analysis (e.g., type 1 vs all others)\n",
    "y_binary = (y == 1).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "probabilities = model.predict_proba(X_test_scaled)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# Function to calculate metrics at various thresholds\n",
    "def evaluate_threshold(threshold):\n",
    "    y_pred = (probabilities >= threshold).astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "# Evaluate at different thresholds\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "results = {thresh: evaluate_threshold(thresh) for thresh in thresholds}\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\anaconda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\anaconda\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.2: (0.27906976744186046, 0.2619047619047619, 1.0),\n",
       " 0.3: (0.5116279069767442, 0.34375, 1.0),\n",
       " 0.4: (0.6976744186046512, 0.25, 0.09090909090909091),\n",
       " 0.5: (0.7209302325581395, 0.0, 0.0),\n",
       " 0.6: (0.7441860465116279, 0.0, 0.0),\n",
       " 0.7: (0.7441860465116279, 0.0, 0.0),\n",
       " 0.8: (0.7441860465116279, 0.0, 0.0)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data\n",
    "X = glass_data[['Na']]  # Predictor\n",
    "y = glass_data['Type']  # Target\n",
    "\n",
    "# Since 'Type' is multiclass, we'll make it a binary problem for this analysis (e.g., type 1 vs all others)\n",
    "y_binary = (y == 1).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "probabilities = model.predict_proba(X_test_scaled)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# Function to calculate metrics at various thresholds\n",
    "def evaluate_threshold(threshold):\n",
    "    y_pred = (probabilities >= threshold).astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "# Evaluate at different thresholds\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "results = {thresh: evaluate_threshold(thresh) for thresh in thresholds}\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RI': {0.3: (0.2558139534883721, 0.03928571428571429, 0.14285714285714285),\n",
       "  0.4: (0.046511627906976744, 0.047619047619047616, 0.025974025974025976),\n",
       "  0.5: (0.0, 0.0, 0.0),\n",
       "  0.6: (0.0, 0.0, 0.0),\n",
       "  0.7: (0.0, 0.0, 0.0)},\n",
       " 'Na': {0.3: (0.23255813953488372, 0.047619047619047616, 0.12987012987012986),\n",
       "  0.4: (0.18604651162790697, 0.049689440993788817, 0.1038961038961039),\n",
       "  0.5: (0.0, 0.0, 0.0),\n",
       "  0.6: (0.0, 0.0, 0.0),\n",
       "  0.7: (0.0, 0.0, 0.0)},\n",
       " 'Mg': {0.3: (0.2558139534883721, 0.0541871921182266, 0.14285714285714285),\n",
       "  0.4: (0.023255813953488372, 0.012987012987012988, 0.012987012987012988),\n",
       "  0.5: (0.023255813953488372, 0.047619047619047616, 0.012987012987012988),\n",
       "  0.6: (0.0, 0.0, 0.0),\n",
       "  0.7: (0.0, 0.0, 0.0)},\n",
       " 'Al': {0.3: (0.20930232558139536, 0.04433497536945813, 0.1168831168831169),\n",
       "  0.4: (0.09302325581395349, 0.03007518796992481, 0.05194805194805195),\n",
       "  0.5: (0.0, 0.0, 0.0),\n",
       "  0.6: (0.0, 0.0, 0.0),\n",
       "  0.7: (0.0, 0.0, 0.0)},\n",
       " 'Si': {0.3: (0.2558139534883721, 0.03741496598639456, 0.14285714285714285),\n",
       "  0.4: (0.0, 0.0, 0.0),\n",
       "  0.5: (0.0, 0.0, 0.0),\n",
       "  0.6: (0.0, 0.0, 0.0),\n",
       "  0.7: (0.0, 0.0, 0.0)},\n",
       " 'K': {0.3: (0.23255813953488372, 0.047619047619047616, 0.12987012987012986),\n",
       "  0.4: (0.0, 0.0, 0.0),\n",
       "  0.5: (0.0, 0.0, 0.0),\n",
       "  0.6: (0.0, 0.0, 0.0),\n",
       "  0.7: (0.0, 0.0, 0.0)},\n",
       " 'Ca': {0.3: (0.2558139534883721, 0.03928571428571429, 0.14285714285714285),\n",
       "  0.4: (0.046511627906976744, 0.03571428571428571, 0.025974025974025976),\n",
       "  0.5: (0.0, 0.0, 0.0),\n",
       "  0.6: (0.0, 0.0, 0.0),\n",
       "  0.7: (0.0, 0.0, 0.0)},\n",
       " 'Ba': {0.3: (0.2558139534883721, 0.03928571428571429, 0.14285714285714285),\n",
       "  0.4: (0.0, 0.0, 0.0),\n",
       "  0.5: (0.0, 0.0, 0.0),\n",
       "  0.6: (0.0, 0.0, 0.0),\n",
       "  0.7: (0.0, 0.0, 0.0)},\n",
       " 'Fe': {0.3: (0.2558139534883721, 0.04263565891472868, 0.16666666666666666),\n",
       "  0.4: (0.09302325581395349, 0.05714285714285715, 0.05194805194805195),\n",
       "  0.5: (0.023255813953488372, 0.03571428571428571, 0.012987012987012988),\n",
       "  0.6: (0.0, 0.0, 0.0),\n",
       "  0.7: (0.0, 0.0, 0.0)}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to evaluate different features using Logistic Regression and custom thresholds\n",
    "def evaluate_feature(feature_column):\n",
    "    X = glass_data[[feature_column]]\n",
    "    y = glass_data['Type']\n",
    "    \n",
    "    # Splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Normalizing the feature\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Training the Logistic Regression model\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Using predict_proba to compute probabilities\n",
    "    probabilities = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    # Evaluating different thresholds\n",
    "    threshold_metrics = {}\n",
    "    for thresh in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "        predictions = (probabilities[:, 1] >= thresh).astype(int)\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        prec = precision_score(y_test, predictions, average='macro', zero_division=0)\n",
    "        rec = recall_score(y_test, predictions, average='macro', zero_division=0)\n",
    "        threshold_metrics[thresh] = (acc, prec, rec)\n",
    "    return threshold_metrics\n",
    "\n",
    "# Evaluate all features except 'Type'\n",
    "feature_metrics = {feature: evaluate_feature(feature) for feature in glass_data.columns[:-1]}\n",
    "feature_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7209302325581395, 0.6862179487179487, 0.6165223665223666)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Selecting all features for the model\n",
    "X = glass_data.drop('Type', axis=1)\n",
    "y = glass_data['Type']\n",
    "\n",
    "# Creating a pipeline for preprocessing and logistic regression\n",
    "numeric_features = X.columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Pipeline with preprocessing and classifier\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(random_state=42, max_iter=1000))])\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the logistic regression model on all features\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the test set results and calculating metrics\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "accuracy, precision, recall\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
